{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Random Variables\n",
    "\n",
    "As mentioned in {doc}`definition.ipynb`, we classify random variables based on their range. The reason we do this is that the mathematical tools we use to work such random variables vary depending  on their range. We will start with the easiest type to understand, which is the discrete random variable:\n",
    "\n",
    "````{panels}\n",
    "DEFINITION\n",
    "^^^\n",
    "```{glossary}\n",
    "discrete random variable\n",
    "    A random variable is said to be a *discrete random variable* if its range is finite or countably infinite.\n",
    "```\n",
    "````\n",
    "\n",
    "If $X$ is a discrete random variable, then we can find the probability of any subset of its values by summing over them:\n",
    "\n",
    "$$\n",
    "P(X \\in A)  = \\sum_{x \\in A} P(X = x) \\mbox{ if } A \\subset \\operatorname{Range}(X),\n",
    "$$\n",
    "where we have implicity taken advantage of the fact that the sets $\\left\\{ s \\left \\vert X(s) = x \\right. \\right\\}$ are disjoint sets, as discussed in {doc}`definition.ipynb`.\n",
    "\n",
    "For any Borel set, $B$, we can express $P(B)$ as a finite sum over the values of $X$ that are in $B$ and in the range of $X$, since all other values of $X$ have probability zero:\n",
    "\n",
    "$$\n",
    "P(X \\in B) = \\sum_{x \\in B \\cap \\operatorname{Range}(X)} P(X = x) \\mbox{ if } B \\in \\mathcal{B}.\n",
    "$$\n",
    "\n",
    "Since both $x$ and $P(X=x)$ are real-valued, we define a function called the probability mass function to facilitate calculating these types of probabilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Mass Functions\n",
    "\n",
    "````{panels}\n",
    "DEFINITION\n",
    "^^^\n",
    "```{glossary}\n",
    "probability mass function (PMF)\n",
    "   For a discrete random variable, $X$, the *probability mass function* of $X$ is the function $p_X(x)$ such that $p_X(x) = \\operatorname{Pr}( X=x)$.\n",
    "```\n",
    "````\n",
    "\n",
    "Note that \n",
    "\n",
    "\\begin{align*}\n",
    "\\sum_{x \\in \\operatorname{Range}(X)} p_X(x) &= P\\left[ X(s) \\in \\operatorname{Range}\\left(X \\right) \\right] \\\\\n",
    "&= P\\left[\\left\\{ s \\left \\vert X(s) \\in \\operatorname{Range}\\left(X \\right) \\right.  \\right\\} \\right] \\\\\n",
    "&= P\\left[ s \\in S \\right] \\\\\n",
    "&=1,\n",
    "\\end{align*}\n",
    "\n",
    "as $x$ ranges over all possible values of $X$, the events $\\left\\{s \\left \\vert X(s)=x \\right. \\right\\}$ are mutually exclusive and form a partition S.\n",
    "\n",
    "When there is no confusion, we will drop the explicit mention of the range of $X$ and just write\n",
    "\\begin{align*}\n",
    "\\sum_{x } p_X(x) &= 1.\n",
    "\\end{align*}\n",
    "Similarly, for any set $A \\in \\operatorname{Range}(X)$, we will write\n",
    "\n",
    "$$\n",
    "P(X\\in A) = \\sum_{x\\in A} p_X(x).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a functional definition of a random variable, we can find the probability mass function by:\n",
    "* for each value $x \\in \\operatorname{Range}(X)$, find the set of outcomes for which $X(s)=x$, which we can write as $E_x=\\left\\{ s \\left \\vert X(s) = x \\right. \\right\\}$. Then let $p_X(s) = P(E_x)$.\n",
    "* for each value of $x \\notin \\operatorname{Range}(X)$, let $p_X(s) = 0$.\n",
    "\n",
    "We illustrate this with some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Example 1**\n",
    "\n",
    "Find the PMF for a binary RV $X(s)$ from tossing a fair coin.  This was Example 1 in {doc}`definition.ipynb`. Please refer to that example for the detailed mathematical formulation of the probability space and functional definition of the random variable. Here, I only reproduce the figure, which illustrates the sample space and the mapping of the outcomes to real values by $X(s)$:\n",
    "\n",
    "```{image} figs/binary-rv1.pdf\n",
    ":alt: Image of handwritten versions of X,Y,Z and x,y,z with upper-case letters drawn without serifs and lower-case letters drawn with curly serifs\n",
    ":width: 600px\n",
    "```\n",
    "\n",
    "From this, we see that $\\operatorname{Range}(X) = \\{ 0, 1\\}$. Hence, we calculate:\n",
    "* $p_X(0) = P\\left[ X(s) = 0 \\right] = P (\\{T\\}) = 1/2$, and\n",
    "* $p_X(1) = P\\left[ X(s) = 1 \\right] = P (\\{H\\}) = 1/2$.\n",
    "\n",
    "Then the PMF for $X$ is given by\n",
    "\n",
    "$$\n",
    "p_X(x) = \n",
    "\\begin{cases}\n",
    "\\frac 1 2, & x \\in \\{0,1\\} \\\\\n",
    "0, & \\mbox{o.w.}\n",
    "\\end{cases}.\n",
    "$$\n",
    "\n",
    "**Note that we often abbreviate \"otherwise\" in such formula as \"o.w.\".**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- $$p_X(x) = P(X=x) = \\begin{cases}\\frac{1}{2}, & x=1 \\\\ \\frac{1}{2}, & x=0 \\end{cases}$$ -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 2**\n",
    "\n",
    "Find the PMF of the binary RV $Y$ from Example 2 of {doc}`definition.ipynb` and for which the sample space and functional mapping are illustrated below:\n",
    "\n",
    "```{image} figs/binary-rv2.pdf\n",
    ":alt: \n",
    ":width: 600px\n",
    "```\n",
    "\n",
    "The range of $Y$ is the same as the range of $X$ in Example 1, $\\operatorname{Range}(Y) = \\{0, 1\\}$.  However, the sample space and mapping from outcomes to values of the random variable is different than in Example 1. From the figure, we see that\n",
    "* $p_Y(0) = P\\left[ Y(s) = 0 \\right] = P (\\{TT\\}) = 1/4$, and\n",
    "* $p_Y(1) = P\\left[ Y(s) = 1 \\right] = P (\\{HH, TH, HT \\}) = 3/4$.\n",
    "\n",
    "The PMF for $Y$ is given by\n",
    "\n",
    "$$\n",
    "p_Y(y) = \n",
    "\\begin{cases}\n",
    "\\frac 1 4, & y =0 \\\\\n",
    "\\frac 3 4, & y =1 \\\\\n",
    "0, & \\mbox{o.w.}\n",
    "\\end{cases}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 3**\n",
    "\n",
    "Now consider the random variable $Z$ from Example 3 in {doc}`definition.ipynb`. This random variable is created using the same probability space as the random variable in Example 2, but has a different range, $\\operatorname{Range}(Z) = \\{ 0,1,2\\}$. From the figure, we see that\n",
    "* $p_Z(0) = P\\left[ Z(s) = 0 \\right] = P (\\{TT\\}) = 1/4$, and\n",
    "* $p_Z(1) = P\\left[ Z(s) = 1 \\right] = P (\\{HT, TH\\}) = 1/2$, and\n",
    "* $p_Z(2) = P\\left[ Z(s) = 2 \\right] = P (\\{HH \\}) = 1/4$.\n",
    "\n",
    "Thus, the PMF of $Z$ is\n",
    "$$\n",
    "p_Z(z) = \n",
    "\\begin{cases}\n",
    "\\frac 1 4, & z \\in \\{0,2\\} \\\\\n",
    "\\frac 1 2, & z =1 \\\\\n",
    "0, & \\mbox{o.w.}\n",
    "\\end{cases}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Example 4**\n",
    "\n",
    "In this example, we show how a random variable can be formed directly from the outcomes of a random experiment. In other words, for an experiment with a numerical outcome, we can let $X(s)=s$.\n",
    "\n",
    "Create a probability space by rolling a fair 6-sided die and observing the top face. Let the event class be the power set of the sample space. Let the RV $W$ be defined by $W(s)$ for all $s \\in S$.\n",
    "\n",
    "Then $p_W(w) = P\\left[ W(s) =w \\right] = P( \\{w\\} )$ for $w \\in \\{1,2,3,4,5,6\\}$. Since this is a fair experiment, $P(\\{w\\}) = 1/6.  \n",
    "\n",
    "The PMF for $W$ is\n",
    "$$\n",
    "p_W(w)  =\n",
    "\\begin{cases}\n",
    "\\frac{1}{6}, & w=1,2,\\dots,6 \\\\ \n",
    "0, & \\text{o.w.}\n",
    "\\end{cases}\n",
    "$$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example 5**\n",
    "\n",
    "Recall that discrete random variables can either have a finite range or a countably infinite range. Let's create an example of the latter. \n",
    "\n",
    "Flip a coin until heads occurs. Record the set of outcomes. Then the sample space is \n",
    "\n",
    "$$\n",
    "S = \\left\\{ H, TH, TTH, TTH, TTTH, \\ldots \\right\\}.\n",
    "$$\n",
    "It should be clear that there is no maximum number of flips until the first $H$ occurs, and it should also be intuitive that the shorter sequences are more probable than the latter ones. We know that $P(H)=P(T) = 1/2$, and the results of different flips can be assumed to be independent.  So \n",
    "\\begin{align*}\n",
    "P(H) &= \\frac 1 2 \\\\\n",
    "P(TH) &= \\left( \\frac 1 2 \\right) \\left( \\frac 1 2 \\right)  =\\frac 1 4\\\\ \n",
    "P(TTH) &= \\left( \\frac 1 2 \\right) \\left( \\frac 1 2 \\right) \\left( \\frac 1 2 \\right)   =\\frac 1 8\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Let's introduce some notation. If a given sequence has $n-1$ $T$ followed by one $H$, we will write it as $T^{n-1}H$. Then \n",
    "\n",
    "$$\n",
    "P(T^{n-1}H) = \\frac{1}{2^{n}}.\n",
    "$$\n",
    "\n",
    "Let $N$ be a random variable that is equal to the number of flips until the first H occurs. Then if $n \\in \\{1,2,3,\\ldots \\}$,\n",
    "\n",
    "\\begin{align}\n",
    "P\\left[N(s) =n \\right] &= P\\left[ T^{n-1}H \\right] \\\\\n",
    "&= \\left( \\frac {1}{2} \\right)^n.\n",
    "\\end{align}\n",
    "\n",
    "The PMF of $N$ is \n",
    "\n",
    "$$\n",
    "p_N(n) = \n",
    "\\begin{cases}\n",
    "\\left( \\frac {1}{2} \\right) ^ n, & n = 1,2,3, \\ldots\\\\\n",
    "0, & \\mbox{o.w.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability mass function is nice because\n",
    "* Its outputs are probabilities of the values that the random variable takes on.\n",
    "* It is easy to calculate the probability of a discrete random variable taking on any of a small set of values by summing over the pmf outputs for those values.\n",
    "* We know the range of the PMF is between 0 and 1 because its outputs are probabilities.\n",
    "\n",
    "However, we will find that the probability mass function is not the best or most appropriate tool in all cases:\n",
    "* It is not as convenient if we are interested in large intervals, such as if we want to evaluate $P(3 < N  \\le 100$. A computer can evaluate this range easily, but it is not easy to calculate by hand (even with a calculator).\n",
    "* We will soon see that the pmf does not generalize to random variables for which the range is an uncountable set of values.\n",
    "\n",
    "\n",
    "Thus, we are motivated to explore other functions  that can address these last concerns. In the next section, we introduce the *cumulative distribution function (CDF)*, which instead of computing $P(X=x)$ computes the probabilities of the form $P(X \\le x)$. We will show that the CDF resolves the problems we identified with the PMF.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
