{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Hypothesis Testing with Real Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with data from different groups, we will generally observe differences. For instance, we may measure the means or medians of the data sets and we will usually find that these summary statistics are different.  At this point, we wish to understand whether the observed difference is \"significant\": is this difference a property of the underlying groups or is it just caused by random variations in the data?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is included here but hidden because a reader of the book can work straight\n",
    "# through with the same variables, but for users downloading the notebooks, this\n",
    "# separate Juypter notebook needs to recreate those variables from the CSV file\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "df=pd.read_csv(\n",
    " \"https://raw.githubusercontent.com/jmshea/intro-data-science-for-engineers/main/03-first-data/covid-merged.csv\")\n",
    "df.set_index(\"state\", inplace=True)\n",
    "df[\"cases_norm\"]=df[\"cases\"]/df[\"population\"]*1000\n",
    "df[\"gdp_norm\"]=df[\"gdp\"]/df[\"population\"]*1000;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in Chapter 2, the number of samples of random phenomena has a significant impact on how accurately we can estimate those phenomena. When it comes to real data, the problem is amplified because we do not know the ground-truth characterization of the random phenomena that is producing the data. \n",
    "\n",
    "Let's start by restricting our analysis to a very small subset of our data to see how effects observed with small data may be caused simply by random sampling. By restricting our data, we can show examples of the technique that we will be using, and the examples will be small enough to easily understand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Data Example Using Covid Rates\n",
    "\n",
    "\n",
    "Consider the normalized Covid case rates from the first six states, and partition them into two sets using alphabetical order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "      <th>urban</th>\n",
       "      <th>cases_norm</th>\n",
       "      <th>gdp_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alabama</th>\n",
       "      <td>7068</td>\n",
       "      <td>4903185</td>\n",
       "      <td>230750.1</td>\n",
       "      <td>59.04</td>\n",
       "      <td>1.441512</td>\n",
       "      <td>47.061267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska</th>\n",
       "      <td>353</td>\n",
       "      <td>731545</td>\n",
       "      <td>54674.7</td>\n",
       "      <td>66.02</td>\n",
       "      <td>0.482540</td>\n",
       "      <td>74.738670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arizona</th>\n",
       "      <td>7648</td>\n",
       "      <td>7278717</td>\n",
       "      <td>379018.8</td>\n",
       "      <td>89.81</td>\n",
       "      <td>1.050735</td>\n",
       "      <td>52.072199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cases  population       gdp  urban  cases_norm   gdp_norm\n",
       "state                                                             \n",
       "Alabama   7068     4903185  230750.1  59.04    1.441512  47.061267\n",
       "Alaska     353      731545   54674.7  66.02    0.482540  74.738670\n",
       "Arizona   7648     7278717  379018.8  89.81    1.050735  52.072199"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=df.loc[:\"Arizona\"]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cases</th>\n",
       "      <th>population</th>\n",
       "      <th>gdp</th>\n",
       "      <th>urban</th>\n",
       "      <th>cases_norm</th>\n",
       "      <th>gdp_norm</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Arkansas</th>\n",
       "      <td>3281</td>\n",
       "      <td>3017804</td>\n",
       "      <td>132596.4</td>\n",
       "      <td>56.16</td>\n",
       "      <td>1.087214</td>\n",
       "      <td>43.938042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>50470</td>\n",
       "      <td>39512223</td>\n",
       "      <td>3205000.1</td>\n",
       "      <td>94.95</td>\n",
       "      <td>1.277326</td>\n",
       "      <td>81.114143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colorado</th>\n",
       "      <td>15207</td>\n",
       "      <td>5758736</td>\n",
       "      <td>400863.4</td>\n",
       "      <td>86.15</td>\n",
       "      <td>2.640684</td>\n",
       "      <td>69.609616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cases  population        gdp  urban  cases_norm   gdp_norm\n",
       "state                                                                 \n",
       "Arkansas     3281     3017804   132596.4  56.16    1.087214  43.938042\n",
       "California  50470    39512223  3205000.1  94.95    1.277326  81.114143\n",
       "Colorado    15207     5758736   400863.4  86.15    2.640684  69.609616"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=df.loc[\"Arkansas\":\"Colorado\"]\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data is so small, histograms do not make sense. Instead, we directly turn to using summary statistics. The means for these data sets are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9915956672540028"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"cases_norm\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6684081069437913"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[\"cases_norm\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the mean Covid case rate for states in group $b$ is much larger then for states in group $a$. The difference is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6768124396897884"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff=b[\"cases_norm\"].mean()-a[\"cases_norm\"].mean()\n",
    "diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing such a large difference, we would like to consider possible hypotheses (possible explanations) for the difference. Some possible hypotheses for the observed difference between groups $a$ and $b$ are:\n",
    "1. States that come later alphabetically might have higher Covid rates. It seems hard to justify why that would be the case, thought.\n",
    "2. The states in group $b$ might differ from the states in group $a$ in some significant way. This could be the case, but we might want to consider another possibility first.\n",
    "3. The differences might just caused by random sampling. That is, the Covid rates all come from the same underlying random phenomena, but because of randomness, some states end up with higher rates in the observed data than others. In the groups $a$ and $b$, it just happened by randomness that $b$ ended up with more higher rates, and $a$ ended up with more lower rates.\n",
    "\n",
    "In statistics, we want to create hypotheses that can be *tested*, which means that we can assess the likelihood that the hypothesis true or false.  In this case, we use the term *statistical hypothesis*:\n",
    "\n",
    "````{panels}\n",
    "DEFINITION\n",
    "^^^\n",
    "statistical hypothesis\n",
    ": an explanation for phenomena observed in a data set that can be formally tested using the data\n",
    "```` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis 3 is a very common type of statistical hypothesis when working with two groups of data that have different values for some summary statistic of interest. This type of hypothesis is called the *null hypothesis*:\n",
    "\n",
    "\n",
    "````{panels}\n",
    "DEFINITION\n",
    "^^^\n",
    "null hypothesis (for multiple groups)\n",
    ": the hypothesis that the feature(s) being measured come from the same random phenomena; any observed differences come from issues related to random sampling, such as having sets that are too small to accurately measure the true value of some summary statistic\n",
    "```` \n",
    "\n",
    "It is helpful to introduce mathematical notation to refer to hypotheses. The null hypothesis is usually denoted by $H_0$, which is typically read as \"H naught\". Intuitively, the zero can be read as implying zero difference between the populations (in the feature being compared).\n",
    "\n",
    "When there is a null hypothesis, we typically compare it with the hypothesis that the feature being measured comes from random phenomena that differ between the two groups. We call this the *alternative hypothesis* and denote it by $H_a$.\n",
    "\n",
    "Usually, $H_a$ cannot be tested directly because we do not know ahead of time *how* the underlying phenomena differ. Thus, we will usually conduct tests by assuming the null hypothesis is true. Then, apply an approach similar to falsification in the nature sciences: we try to test whether the null hypothesis is true, and a result that it is likely false would imply that the alternative hypothesis is likely true. (Note that I use \"likely\" here as informal way of introducing the fact that we will not be able to make any hypotheses as being absolutely true: we will only be able to estimate the probabilities of hypotheses.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing under the assumption that $H_0$ is true is called *null hypothesis testing*. There are several methods to test the null hypothesis. Before introducing the technique we will use, we note that statistical methods can generally be put into one of two categories:\n",
    "1. In *model-based* methods, we assume that (under $H_0$), the summary statistics we use will fit certain statistical models, and we can typically use those models to produce an analytic estimate for the probability of observing such a large difference in the observed summary statistics.\n",
    "2. In *model-free* methods, we use techniques to estimate the probability of seeing such a large difference without assuming any model for the summary statistics, but instead make other assumptions, such as that samples from the data itself can represent samples from the underlying random phenomena.\n",
    "\n",
    "It is important to note that either approach will rely on assumptions. However, we will use the model-free method because it has several important advantages:\n",
    "1. It does not require certain size data before the model is accurate.\n",
    "2. It does not require analytical models for every summary statistic that may be considered.\n",
    "3. It does not rely on mathematical formulas that may seem obscure or that require a significant amount of foundational work in probability to understand.\n",
    "4. The model-free approach we will use is easier to get started with, especially for engineers who are experience programming and simulating phenomena.\n",
    "\n",
    "The approach we will use is called *resampling*:\n",
    "\n",
    "\n",
    "````{panels}\n",
    "DEFINITION\n",
    "^^^\n",
    "resampling\n",
    ": Resampling is a type of statistical simulation in which new samples are repeatedly drawn from the existing data for each of the groups under consideration, and the statistical measures being used are evaluated for each of the new sample groups. \n",
    "```` \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using two-group null hypothesis testing via resampling, our assumption is that the data in the two groups come from the same underlying random phenomena. Thus, we can pool the data from the two groups, and then we draw samples from the pooled data to represent samples from the underlying random phenomena. \n",
    "\n",
    "We can put all the data into one long NumPy array by horizontally stacking the data. To do this we use NumPy's `hstack` function:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.441512  , 0.48254038, 1.05073463, 1.08721441, 1.27732626,\n",
       "       2.64068365])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled=np.hstack((a[\"cases_norm\"], b[\"cases_norm\"]))\n",
    "pooled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have numerical data, we leverage the `numpy.random` library to draw samples, which we will import as `npr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as npr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random number generators, such as the one used by `numpy.random` actually produce a sequence of pseudo-random numbers, which look random but are actually deterministic if the internal state of the random number generator is known. This internal state can be set using a \"seed\". To allow readers to obtain the same results as those shown in this book, I set the seed of the random number generator as shown below. However, be aware that if you re-run cells or run cells out of order, you will get different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "npr.seed(21341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can randomly draw data from `pooled` using `npr.choice`, which requires a variable to draw from as the first argument and can take a second argument as the number of items to draw (if not given, the default is one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.05073463, 1.05073463, 2.64068365])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npr.choice(pooled, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the resulting array has a repeated value, even though all the values in `pooled` are different. There are two ways to sample from data:\n",
    "1. **Sampling with replacement:** Items drawn are placed back into the array from which data is being sampled. Any number of items may be drawn.\n",
    "2. **Sampling without replacement:** Items drawn are removed from the array from which data is being sampled. The maximum number of items that can be drawn is the size of the original array.\n",
    "\n",
    "`npr.choice` defaults to sampling with replacement, but can use sampling without replacement by passing the keyword argument `replace=False`.\n",
    "\n",
    "For example, here are two draws of 6 items using each approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.27732626 0.48254038 1.05073463 1.27732626 1.27732626 0.48254038]\n",
      "[1.05073463 1.27732626 1.08721441 0.48254038 1.441512   2.64068365]\n"
     ]
    }
   ],
   "source": [
    "npr.seed(21398475)\n",
    "print(npr.choice(pooled, 6))\n",
    "print(npr.choice(pooled, 6, replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform resampling, we create new groups to represent $a$ and $b$, but where the samples are drawn from the pooled data. In this chapter, we use the most popular method, which is drawing the data **with replacement**.  This is commonly called **bootstrap sampling**. When creating the new groups, it is important to use the same sizes as the original groups. Here is what one draw looks like.\n",
    "\n",
    "Try running the cell below a few times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a: [1.05073463 1.05073463 2.64068365]\n",
      "new b: [2.64068365 1.27732626 1.08721441]\n"
     ]
    }
   ],
   "source": [
    "alen=len(a)\n",
    "blen=len(b)\n",
    "newa=npr.choice(pooled, alen)\n",
    "newb=npr.choice(pooled, blen)\n",
    "print(\"new a:\", newa)\n",
    "print(\"new b:\", newb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to determine whether the observed difference in summary statistics could be attributed just to randomness. We want to use resampling to determine how often we see such a large difference under $H_0$. Copy the cell from above and then add the line shown at the end of the cell below to print out the difference in means. Run the cell below a few times to see what can happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a: [1.05073463 1.05073463 0.48254038]\n",
      "new b: [2.64068365 1.05073463 1.08721441]\n",
      "original diff 0.6768124396897884\n",
      "new diff 0.7315410188646995\n"
     ]
    }
   ],
   "source": [
    "alen=len(a)\n",
    "blen=len(b)\n",
    "newa=npr.choice(pooled, alen)\n",
    "newb=npr.choice(pooled, blen)\n",
    "print(\"new a:\", newa)\n",
    "print(\"new b:\", newb)\n",
    "\n",
    "print(\"original diff\", diff)\n",
    "print(\"new diff\", newb.mean() -newa.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note is that the new difference can be either positive or negative. We previously mentioned that we want to determine \"how often we see such a large difference\", but this turns out to be ambiguous, because we could use the magnitude (absolute value) of the new difference or we could use the signed new difference. For now, let's use the magnitude, which is called a two-sided test. I will have more to say about one-sided tests vs. two sided tests in <span style=\"color:red\">Chapter 5 (tentative)</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Now, we will see how to build a simulation to estimate the probability of seeing such a large difference in sample means under $H_0$. This probability is called the $\\mathbf{p}$**-value**. For now, we will say that the difference is statistically significant if the observed $p$-value is smaller than a threshold.\n",
    "\n",
    "An important part of statistical testing is to declare what is being tested and what the criterion is for statistical significance **before** performing the statistical tests. Thus, we need to determine the $p$-value threshold **before** running the simulation. For instance, if $H_0$ is true and we see differences as large as we observed in our data 10% of the time, should we consider the observed difference significant? What if it were only 5% of the time? How about only 1% of the time? There is no right answer to that question. The threshold for rejecting \n",
    "will determine the maximum probability that we will allow for making the error of rejecting the null hypothesis when it is actually true. For instance if the threshold is 10%, then if there is no actual difference between the groups for the random phenomena being measured, a difference in summary statistics as large as the one observed could still occur as often as 10% of the time. In many scientific fields, a $p$-value threshold of 5% is used. In this book, I will use a $p$-value threshold of 1%, which can be considered to be more \"strict\" in the sense that we are less likely to reject the null hypothesis.\n",
    "\n",
    "Note that if the estimated $p$-value is above the threshold, that does not mean that the null hypothesis is true or that the alternative hypothesis is false. We say that we \"fail to reject the null hypothesis\". In many such cases, the null hypothesis will actually be false but we just do not have enough data to support rejecting the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these details out of the way, we can build our simulation. As in Chapter 2, the simulation is a `for` loop in which each iteration of the for loop represents one random draw. Here, each random draw is to create two groups $\\tilde{a}$ and $\\tilde{b}$ by drawing from the pooled data. For each draw, we calculate the averages, and we use a counter to track how often we observe an absolute difference in means that is large as we observed in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.1993\n"
     ]
    }
   ],
   "source": [
    "# These are common to most simulation:\n",
    "# 1) Set up the number of iterations (draws from the pool) \n",
    "# 2) Initialize our counter to zero\n",
    "num_sims=10_000\n",
    "count=0\n",
    "\n",
    "# Put these outside the loop to save execution time, since they don't change\n",
    "alen=len(a)\n",
    "blen=len(b)\n",
    "\n",
    "\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    # Bootstrap sampling \n",
    "    newa=npr.choice(pooled, alen)\n",
    "    newb=npr.choice(pooled, blen)\n",
    "    \n",
    "    # Calculate the absolute value of the difference of means\n",
    "    newdiff= abs( newa.mean() - newb.mean() )\n",
    "    \n",
    "    # Update the counter if it exceeds the difference from the original groups\n",
    "    if newdiff >=diff:\n",
    "        count+=1\n",
    "        \n",
    "print(\"Prob. of seeing a result this extreme =~\", count/num_sims)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell above a few times. The results will vary, but should be close to 0.2. Since this $p$-value is much larger than our threshold of 1% (i.e., 0.01), we **fail to reject the null hypothesis**. The observed difference will occur approximately 20% of the time even if there is no difference in normalized Covid rates among these states."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Observed Differences in Covid Rates\n",
    "\n",
    "Now let's apply bootstrap resampling to test the previous observed differences in covid rates based on GDP per population:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gdp=df[\"gdp_norm\"].median()\n",
    "m_gdp\n",
    "higher_gdp = df[ df[\"gdp_norm\"]> m_gdp ]\n",
    "lower_gdp = df[ df[\"gdp_norm\"]<= m_gdp ]\n",
    "hgdp_mu=higher_gdp[\"cases_norm\"].mean()\n",
    "lgdp_mu=lower_gdp[\"cases_norm\"].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, we previously found the mean Covid rates per population for higher GDP and lower GDP states to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.511232264232122, 1.9258062634390536)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgdp_mu, lgdp_mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of our binary hypothesis test is to calculate the difference in means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5854260007930685"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_gdp = hgdp_mu - lgdp_mu\n",
    "diff_gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this case, the pooled data is simply all of the normalized Covid data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled_covid=df[\"cases_norm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the simulation from the previous section and modify it to draw data to represent new `higher_gdp` and `lower_gdp` groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.0756\n"
     ]
    }
   ],
   "source": [
    "# These are common to most simulation:\n",
    "# 1) Set up the number of iterations (draws from the pool) \n",
    "# 2) Initialize our counter to zero\n",
    "num_sims=10_000\n",
    "count=0\n",
    "\n",
    "# Put these outside the loop to save execution time, since they don't change\n",
    "hlen=len(higher_gdp)\n",
    "llen=len(lower_gdp)\n",
    "\n",
    "\n",
    "\n",
    "for sim in range(num_sims):\n",
    "    # Bootstrap sampling \n",
    "    newh=npr.choice(pooled_covid, hlen)\n",
    "    newl=npr.choice(pooled_covid, llen)\n",
    "    \n",
    "    # Calculate the absolute value of the difference of means\n",
    "    newdiff= abs( newh.mean() - newl.mean() )\n",
    "    \n",
    "    # Update the counter if it exceeds the difference from the original groups\n",
    "    if newdiff >=diff_gdp:\n",
    "        count+=1\n",
    "        \n",
    "print(\"Prob. of seeing a result this extreme =~\", count/num_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the simulation a few times. The results should vary but will generally be around 0.07 ( 7%). Since this is larger than our $p$-value threshold of 1%, we fail to reject the null hypothesis. We cannot be sure that higher per-capita GDP is associated with higher per-capita Covid rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulation code above can easily be turned into a function that can be applied to any data when we are using resampling to perform a two-sided test for an observed differencce of means. To make this into a function:\n",
    "1. Click in the cell with the simulation above and choose \"Copy Cells\" from Jupyter's Edit menu. (Alternatively, you can use the Copy command from your Browser's Edit menu or the corresponding keyboard shortcut.)\n",
    "2. Paste it into a new cell block using \"Paste Cells Below\" from the Edit menu. (If you used the Copy command from your Browser, then click in an empty cell and use  your browser's Paste command.)\n",
    "3. The simulation code will be the body of the new function, and so it will need to be indented. Select the entire contents of the simulation code in the new cell using your mouse, the Select All command from your browser's Edit menu, or the keyboard shortcut. Then press the keyboard shortcut to indent the block (Control-] or Command-]).\n",
    "4. Add a function signature at the top to name your function and determine the arguments. Provide arguments for the pooled data, the observed mean difference, and the number of observations in each group. It is also helpful to make the number of simulation iterations be an argument of the function in case we need to run more iterations to accurately estimate the $p$-value.\n",
    "5. I have revised the names of the variables inside the function to make them more generic, and I recommend you do the same.\n",
    "\n",
    "The final function should look as follows:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_mean(data, diff, len1, len2, num_sims=10_000):\n",
    "    count=0\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        # Bootstrap sampling \n",
    "        group1=npr.choice(data, len1)\n",
    "        group2=npr.choice(data, len2)\n",
    "\n",
    "        # Calculate the absolute value of the difference of means\n",
    "        newdiff= abs( group1.mean() - group2.mean() )\n",
    "\n",
    "        # Update the counter if it exceeds the difference from the original groups\n",
    "        if newdiff >=diff:\n",
    "            count+=1\n",
    "\n",
    "    print(\"Prob. of seeing a result this extreme =~\", count/num_sims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this function to test our observation for per-capita GDP as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.0722\n"
     ]
    }
   ],
   "source": [
    "resample_mean(pooled_covid, diff_gdp, len(higher_gdp), len(lower_gdp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply bootstrap resampling when the states are grouped using the urban index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_urban=df[\"urban\"].median()\n",
    "higher_urban=df[ df[\"urban\"]>m_urban ]\n",
    "lower_urban =df[ df[\"urban\"]<= m_urban]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.8908656178327066, 1.5461729098384682)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "higher_urban[\"cases_norm\"].mean(), lower_urban[\"cases_norm\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3446927079942386"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_urban=higher_urban[\"cases_norm\"].mean() - lower_urban[\"cases_norm\"].mean()\n",
    "diff_urban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our `resample_mean()` function to perform the two-sided test via bootstrap resampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.0087\n"
     ]
    }
   ],
   "source": [
    "resample_mean( pooled_covid, diff_urban, len(higher_urban), len(lower_urban) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The observed $p$-value is close to 0.01, which is our threshold, and some simulations may exceed 0.01. We need to determine the $p$-value more accurately, which can be achieved by using more simulation iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.00913\n"
     ]
    }
   ],
   "source": [
    "resample_mean( pooled_covid, diff_urban, len(higher_urban), len(lower_urban),\n",
    "               num_sims=100_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the additional simulation iterations, the $p$-value is found to be approximately 0.009, which is below our threshold. Therefore, we reject the null hypothesis, and we can say that the groupings based on the Urban index  are associated with differences in the mean per-capita Covid rates that are statistically significant at the $p<0.01$ level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribution of the bootstrap mean-difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time we create a bootstrap value for the difference of means, we create a new random value. Let's see how the bootstrap means are distributed by modifying our simulation to also produce a histogram of those values. Copy the simulation from above, update the function name, and add the marked lines to store every mean difference and plot the histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_mean_hist(data, diff, len1, len2, num_sims=10_000):\n",
    "    count=0\n",
    "    sample_means=[] # New variable to store sample means\n",
    "\n",
    "    for sim in range(num_sims):\n",
    "        # Bootstrap sampling \n",
    "        group1=npr.choice(data, len1)\n",
    "        group2=npr.choice(data, len2)\n",
    "\n",
    "        # Calculate the absolute value of the difference of means\n",
    "        newdiff= abs( group1.mean() - group2.mean() )\n",
    "        \n",
    "        sample_means += [ group1.mean() - group2.mean() ] # Store sample mean\n",
    "\n",
    "        # Update the counter if it exceeds the difference from the original groups\n",
    "        if newdiff >=diff:\n",
    "            count+=1\n",
    "\n",
    "    print(\"Prob. of seeing a result this extreme =~\", count/num_sims)\n",
    "    plt.hist(sample_means, 40) # Plot the histogram with 40 bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the histogram does not depend on the mean difference observed in the data. Since the pooled data and the group sizes are the same for both the GDP grouping and the Urban index grouping, both will produce the same histograms (up to variations from the random sampling). Let's call the new function with the arguments used for the urban index data. Because the focus of this simulation is the histogram and 10,000 points will already produce a very detailed histogram, we leave `num_sims` set to the default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prob. of seeing a result this extreme =~ 0.0084\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resample_mean_hist( pooled_covid, diff_urban,\n",
    "                    len(higher_urban), len(lower_urban) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few obervations:\n",
    "    \n",
    "1. The difference of means has a bell shape -- we saw that before. Why do you think that is?\n",
    "2. The majority of the values fall between -2 and +2. Thus, it is not surprising that getting a mean-difference as large as 2.34 is rare.\n",
    "\n",
    "Later in the book, we will investigate how we can use the histogram to provide confidence intervals on the mean difference under the null hypothesis. This is a way to provide more information about how an observed difference in means compares to what is expected under the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Assignment\n",
    "\n",
    "* [Exploring Histograms](https://tinlizzie.org/histograms/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
