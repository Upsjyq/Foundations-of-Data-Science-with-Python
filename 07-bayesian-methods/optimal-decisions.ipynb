{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fba2df4-38af-4288-9442-1f80868b6ca7",
   "metadata": {},
   "source": [
    "#  Optimal Decisions for Discrete Stochastic Systems\n",
    "\n",
    "We are ready to tackle our third example from this chapter's introduction: \n",
    "\n",
    "```{note}\n",
    "In a binary communication system, 0s and 1s are transmitted over a noisy channel. If we know the probability that a given bit is a 0 and we know the probabilities associated with the noisy channel, what is the optimal decision given an observation at the output of the channel?\n",
    "```\n",
    "\n",
    "Let's start by considering one particular instantiation of this problem: \n",
    "\n",
    "## Binary Communication System\n",
    "\n",
    "Suppose we are given a system with that has binary inputs and ternary outputs. Let's use $A_0$ and $A_1$ to denote the input events and $B_0$, $B_1$, and $B_2$ to denote the output events. The channel is completely specified by giving the likelihoods, $P(B_j|A_i)$ for all $i \\in \\{0,1\\}$ and $j \\in \\{0,1,2\\}. \n",
    "\n",
    "Let $p_{ij} = P(B_j|A_i)$. Note the order of the $i$ and $j$.  This is the probability of transitioning from input $i$ to output $j$, and these are also called *channel transition probabilities*. It is helpful to visualize the channel transition probabilities/likelihoods on a diagram, where we label the arrow connecting input event $A_i$ with output event $B_j$ by $p_{ij}$. An  example of such a diagram is shown in {numref}`example2to3`. For example, from this diagram, we can read that $p_{00}=5/8$, $p_{01}=1/4$, and $p_{12}=3/4$.\n",
    "\n",
    ":::{figure-md} example2to3\n",
    "\n",
    "<img src=\"example2to3.svg\" alt=\"Channel diagram with two inputs ($A_0, A_1$) and three outputs ($B_0, B_1, B_2$). Probabilities are shown for each transition.\" width=\"400px\">\n",
    "\n",
    "Example channel transition diagram for channel with two inputs and three outputs.\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d4ab4-209e-4fa8-a2b6-02501a38581c",
   "metadata": {},
   "source": [
    "It is convenient to collect the channel transition probabilities into an array, such that the $(i,j)$th entry in the array is $p_{ij}$. Let's import numpy and create an array with these channel transition probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "691b77c6-b604-429e-9fed-6927d32cde2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.625 0.25  0.125]\n",
      " [0.125 0.125 0.75 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "P=np.array([\n",
    "    [5/8, 1/4, 1/8],\n",
    "    [1/8, 1/8, 3/4]\n",
    "])\n",
    "\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73defdc4-e781-493a-abe4-6f810699cf7d",
   "metadata": {},
   "source": [
    "Note that the probabilities with the same conditioning should add to 1. In other words,\n",
    "\n",
    "$$\n",
    "\\sum_{j \\in \\{0,1,2\\} }  P(B_j|A_i) = 1, ~~~ i=0,1.\n",
    "$$\n",
    "In the diagram, this corresponds to the transition probabilities that emerge from the same input. In the matrix $\\mathbf{P},$ this corresponds to all of the entries in a row. We can tell numpy to sum the array across the column by using the `np.sum` function and passing the `axis=1` argument to tell it to sum across the second axis (the columns):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65408bd6-5abd-47e8-9026-2a3ec9b9c7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(P, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8418e06-4bd9-4c10-a4e6-d14fde3a671f",
   "metadata": {},
   "source": [
    "Note that the probabilities for a particular $B_j$ (i.e., merging into a particular output) do not necessarily sum to 1.\n",
    "\n",
    "\n",
    "$$\n",
    "\\sum_{i \\in \\{0,1\\} }  P(B_j|A_i) = ?, ~~~ j=0,1,2.\n",
    "$$\n",
    "\n",
    "This corresponds to the column sums of the matrix $\\mathbf{P}$, and we can get these column sums by using the `np.sum` function and passing the `axis=0` argument to tell numpy to sum across axis 0 (the rows):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87fb8f05-38f4-4355-bdc4-818a0091ca33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.75 , 0.375, 0.875])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(P, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe417923-67e6-42c8-81ab-c95a8f90c6d2",
   "metadata": {},
   "source": [
    "## Decision Problem and Optimal Solutions\n",
    "\n",
    "The *decision problem* for the binary communication systems is concisely described as follows: given the observed output, determine which input was sent.  A *decision rule* tells how to choose an input given an observed output. In general, a decision rule may result in a randomized choice for the input,  but in this class, we will only consider deterministic decision rules.  \n",
    "\n",
    "We can turn this into an *optimal decision problem* if we specify criteria to be optimized. Here are two common criteria:\n",
    "1. Maximize the likelihood of the input \n",
    "2. Choose the input that minimizes the probability of error\n",
    "\n",
    "The optimum decision under criterion 1 is called the *maximum likelihood (ML)* decision. We can formulate it directly using the likelihoods, which were given in {numref}`example2to3`.  For each output, we are choosing the input that has the largest likelihood, which corresponds to the arrow with the largest probability merging into that output in {numref}`example2to3`. Similarly, the ML decision corresponds to the row number with the largest probability for each column of the transition probability matrix, $\\mathbf{P}$. To get the index of the largest value in each column, we can use the `np.argmax` function and pass the `axis=0` keyword parameter to tell NumPy to maximize over the rows. (Note that `np.max` would return the maximum value, whereas `np.argmax` returns the index of the maximum value.)\n",
    "\n",
    "Thus, the ML decisions are as follows:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ddfa7d8-0220-4fed-89a5-f2661d928ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(P, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4487a0-1d10-4cc6-83be-d9438692ab5b",
   "metadata": {},
   "source": [
    "Given $B_0$ is received decide $A_0$\n",
    "\n",
    "Given $B_1$ is received, decide $A_0$\n",
    "\n",
    "Given $B_2$ is received, decide $A_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c30bd-c6d6-4fcc-99f6-01f783858403",
   "metadata": {},
   "source": [
    "Unfortunately, the ML solution does not necessarily minimize the probability of error. For instance, suppose that we know that 0 is sent with probability 1; i.e., $P(A_0)=1$. Then the ML rule will make an error whenever $B_2$ is received. Let's use total probability to calculate the probability of each $B_j$:\n",
    "\n",
    "$$\n",
    "P(B_j) = \\sum_{i \\in \\{0,1\\}} P(B_j|A_i) P(A_i)\n",
    "$$\n",
    "\n",
    "We start by setting up a NumPy vector to hold the *a priori* probabilities: \n",
    "\n",
    "$$ \n",
    "\\left[ P(A_0), P(A_1) \\right].\n",
    "$$\n",
    "\n",
    "Then we use a nested for loop to calculate $P(B_j)$ for each $j$ and within the loop for each $j$ we use a for loop to  carry out the sum for each $i$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49ff585a-5e4d-45ba-9a52-1e438900d8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(B0) = 0.625\n",
      "P(B1) = 0.25\n",
      "P(B2) = 0.125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aprioris = np.array([1,0])\n",
    "for j in range(3):\n",
    "    pBj=0\n",
    "    for i in range(2):\n",
    "        pBj+=P[i,j]*aprioris[i]\n",
    "    \n",
    "    print(f'P(B{j}) = {pBj}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f5b9ca-2b93-40aa-ac15-88bab0ad052f",
   "metadata": {},
   "source": [
    "Let $E$ be the event that an error occurs (i.e., the decision differs from the transmitted symbol). Then for this simple example, $P(E) =  P(B_2) = 0.125$. We know that it is suboptimal, because we could just use the decision rule \"Always decide $A_0$\" and get error probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f95e79-671a-45d3-8d74-95fac69a570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aprioris = np.array([1/4,3/4])\n",
    "aprioris = np.array([1/5,4/5])\n",
    "for j in range(3):\n",
    "    pBj=0\n",
    "    for i in range(2):\n",
    "        pBj+=P[i,j]*aprioris[i]\n",
    "    print(f'P(B{j}) = {pBj}')\n",
    "    for i in range(2):\n",
    "        print(f'P(A{i}|B{j}) = {P[i,j]*aprioris[i]/pBj}')\n",
    "    print()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8df278-d14c-45ed-959b-c58f4398f699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
