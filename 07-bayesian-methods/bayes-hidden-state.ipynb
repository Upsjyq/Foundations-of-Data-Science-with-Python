{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f6a581-a4df-4f5e-8102-bf4eb9e38451",
   "metadata": {},
   "source": [
    "# Bayes' Rule in Systems with Hidden State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3840043f-bde3-4029-8b3d-1f6edfbf3e81",
   "metadata": {},
   "source": [
    "When a system has some form of memory, we refer to the current value of that memory as the *state* of the system. If that memory cannot be observed, then we call that *hidden state*. Systems with hidden state are different from systems with unknown inputs in that the hidden state can affect more than one output: depending on how the state evolves, it may affect one output, a few outputs, or all outputs.\n",
    "\n",
    "In fact, we have already seen a system with hidden state: the Magician's Coin problem. In this problem, the hidden state is which coin was chosen, and the chosen coin affects all future outputs of the system. Note that although the Magician's Coin does not have both state and input(s), many have both.\n",
    "\n",
    "In this section, I will revisit the Magician's Coin problem to better expose why the observations affect the probabilities of future events in the way they do. This gives us a chance to use Bayes' Rule to explore the probabilities of the hidden state, and it will also give us an opportunity to apply our knowledge about conditional independence. \n",
    "\n",
    "Recall the simple question we started with: **If the coin comes up heads on the first flip, what is the probability that it comes up heads on the second flip?**\n",
    "\n",
    "As before, let $H_i$ be the event that the chosen coin comes up heads on flip $i$. Also, we assume that the magician is equally likely to choose between a fair coin and a two-headed coin. Let $F$ be the event atht eh chosen coin is fair.\n",
    "\n",
    "We are asked to find $P(H_2 |H_1)$. In the previous section, we solved this using the definition of conditional probability and the Law of Total Probability as follows:\n",
    "\n",
    "$$ \n",
    "P(H_2|H_1) = \\frac{P(H_1 \\cap H_2)}{P(H_1)}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "P(H_1) = P(H_1 |F) P(F) + P(H_1 |\\overline{F}) P(\\overline{F}) = 3/4\n",
    "$$\n",
    "and\n",
    "\n",
    "$$\n",
    "P(H_1 \\cap H_2) = P(H_1 \\cap H_2 |F) P(F) + P(H_1 \\cap H_2 |\\overline{F}) P(\\overline{F}) = 5/8\n",
    "$$\n",
    "\n",
    "So, $P(H_2|H_1) = 5/6$. \n",
    "\n",
    "This is the easiest way to solve for $P(H_2|H_1)$. But it is non-intuitive because it tells us nothing about why knowing $H_1$ affects the probability of $H_2$. We previously argued that every time we see an outcome of heads, we should be more likely to believe that we have the two-headed coin (i.e., the probability that we have the two-headed coin should increase).  Only now do we have the tools to test this hypothesis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2cce3a-87cd-4f3c-99cd-85c317fe1b9a",
   "metadata": {},
   "source": [
    "We are interested in $P(\\overline{F}|H_1)$, the probability of having selected the two-headed coin after the first outcome is observed to be heads. We note that we do not have outcomes in this form, but we do have outcomes of the form $P(H_1|\\overline{F})$ and $P(F)$. In fact, these probabilities are a likelihood and an *a priori* probability for this system. So, we can solve the for the desired probability using Bayes' Rule:\n",
    "\n",
    "$$\n",
    "P\\left(\\overline{F} \\left \\vert H_1 \\right. \\right) = \\frac{P \\left( H_1 \\left \\vert \\overline{F} \\right. \\right) P(F)}{P(H_1)}.\n",
    "$$\n",
    "\n",
    "Note that I did not expand the denominator because we have already found $P(H_1)$ using the Law of Total Probability. We already know the probabilities in the numerator, so we can calculate\n",
    "\n",
    "$$\n",
    "P\\left(\\overline{F} \\left \\vert H_1 \\right. \\right) = \\frac{(1)(1/2)}{P(3/4)} = \\frac{2}{3}.\n",
    "$$\n",
    "Thus, after observing a single heads, the probability that the magician has selected the two-headed coin goes from 1/2 to 2/3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d1408d-85b4-48ae-9d4d-6c0f40c8796c",
   "metadata": {},
   "source": [
    "Now, I will show how can apply our knowledge of the updated state probabilities to find the probability of $H_2$. Because of the multiple conditioning that arises, this may be confusing at first. To help with this, I'm going to first hide the conditioning on $H_1$ by defining\n",
    "\n",
    "$$\n",
    "\\tilde{P}(H_2) = P(H_2|H_1)\n",
    "$$\n",
    "Recalling that conditioning on $H_1$ creates a new (conditional) probability measure, $\\tilde{P}$ is a different name for that probability measure.\n",
    "\n",
    "Now, we can apply the Law of Total Probability using $\\{F, \\overline{F} \\}$ as a partition:\n",
    "\n",
    "$$\n",
    "\\tilde{P}(H_2) = \\tilde{P}(H_2|F) \\tilde{P}(F) + \\tilde{P}(H_2 | \\overline{F} ) \\tilde{P} ( \\overline{F})\n",
    "$$\n",
    "\n",
    "Next, we substitute back in that $\\tilde{P}(A) = P(A|H_1)$ for any event $A$. Recall that conditioning on two events results in a single conditioning on the intersection of the two events. Thus, the resulting expression is\n",
    "\n",
    "$$\n",
    "P(H_2|H_1) = P(H_2|H_1 \\cap F) P(F|H_1) + P\\left(H_2 \\left \\vert H_1 \\cap \\overline{F} \\right. \\right) P \\left( \\overline{F} \\left \\vert H_1 \\right. \\right)\n",
    "$$\n",
    "\n",
    "We know $P(\\overline{F}|H_1)=2/3$, and $P(F|H_1) = 1 - P(\\overline{F}|H_1) = 1/3$. But this is where things get tricky -- what are the other two probabilities? We have to apply conditional independence to find these. If we know the true state, $F$ or $\\overline{F}$, then information about what happened on the first flip cannot affect the outcome of the second flip. In other words, $H_2$ is *conditionally independent* of $H_1$ given either $F$ or $\\overline{F}$.  Thus,\n",
    "\n",
    "$$\n",
    "P(H_2|H_1) = P(H_2| F) P(F|H_1) + P\\left(H_2 \\left \\vert  \\overline{F} \\right. \\right) P \\left( \\overline{F} \\left \\vert H_1 \\right. \\right)\n",
    "$$\n",
    "\n",
    "Finally, we are ready to solve:\n",
    "\n",
    "$$\n",
    "P(H_2|H_1) = \\left (\\frac 1 2 \\right) \\left( \\frac 1 3 \\right) +\n",
    "\\left( 1  \\right) \\left( \\frac 2 3 \\right) = \\frac 5 6,\n",
    "$$\n",
    "which is the same answer we got above. However we have a new perspective now. Given $H_1$:\n",
    "* the magician will have the fair coin with probability 1/3, and another flip of that coin will yield heads with probability 1/2, and\n",
    "* the magician will have the two-headed coin with probability 2/3, and another flipt of that coin will yield heads with probability 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e2cf2-bf31-4101-b407-73008dbbd273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
